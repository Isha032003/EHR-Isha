# -*- coding: utf-8 -*-
"""Milestone task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wJWz3X-xxFQBJeuR1usuWnN17m8WkNts
"""

!unzip "/content/archive(1).zip" -d "/content/"

# Import libraries
import cv2
import os
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D

dataset_path = "/content/brain_tumor_dataset/no"  # ‚Üê change to your folder

# Read and resize all images
images = []
for file in os.listdir(dataset_path):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img = cv2.imread(os.path.join(dataset_path, file), cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (256,256))
        images.append(img)

images = np.array(images, dtype='float32') / 255.0
print("Total images loaded:", len(images))

noise_factor = 0.3
noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)
noisy_images = np.clip(noisy_images, 0., 1.)

# Show sample
plt.figure(figsize=(8,4))
plt.subplot(1,2,1); plt.imshow(images[0], cmap='gray'); plt.title("Original")
plt.subplot(1,2,2); plt.imshow(noisy_images[0], cmap='gray'); plt.title("Noisy")
plt.show()

dataset_path = "/content/brain_tumor_dataset/yes"  # ‚Üê change to your folder

# Read and resize all images
images = []
for file in os.listdir(dataset_path):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img = cv2.imread(os.path.join(dataset_path, file), cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (256,256))
        images.append(img)

images = np.array(images, dtype='float32') / 255.0
print("Total images loaded:", len(images))

noise_factor = 0.3
noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)
noisy_images = np.clip(noisy_images, 0., 1.)

# Show sample
plt.figure(figsize=(8,4))
plt.subplot(1,2,1); plt.imshow(images[0], cmap='gray'); plt.title("Original")
plt.subplot(1,2,2); plt.imshow(noisy_images[0], cmap='gray'); plt.title("Noisy")
plt.show()

noise_factor = 0.3
noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)
noisy_images = np.clip(noisy_images, 0., 1.)

# Show sample
plt.figure(figsize=(8,4))
plt.subplot(1,2,1); plt.imshow(images[0], cmap='gray'); plt.title("Original")
plt.subplot(1,2,2); plt.imshow(noisy_images[0], cmap='gray'); plt.title("Noisy")
plt.show()

model = Sequential([
    Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(256,256,1)),
    MaxPooling2D((2,2), padding='same'),
    Conv2D(32, (3,3), activation='relu', padding='same'),
    UpSampling2D((2,2)),
    Conv2D(1, (3,3), activation='sigmoid', padding='same')
])

model.compile(optimizer='adam', loss='binary_crossentropy')
model.summary()

x_train = noisy_images.reshape((-1,256,256,1))
y_train = images.reshape((-1,256,256,1))

model.fit(x_train, y_train, epochs=10, batch_size=8, validation_split=0.1)

enhanced_images = model.predict(x_train)

plt.figure(figsize=(10,5))
plt.subplot(1,3,1); plt.imshow(noisy_images[0], cmap='gray'); plt.title("Noisy")
plt.subplot(1,3,2); plt.imshow(enhanced_images[0].reshape(256,256), cmap='gray'); plt.title("Enhanced")
plt.subplot(1,3,3); plt.imshow(images[0], cmap='gray'); plt.title("Original")
plt.show()

from skimage.metrics import peak_signal_noise_ratio, structural_similarity

results = []

for i in range(len(images)):
    # Compute PSNR
    psnr_before = peak_signal_noise_ratio(images[i], noisy_images[i], data_range=images[i].max() - images[i].min())
    psnr_after = peak_signal_noise_ratio(images[i], enhanced_images[i].reshape(256,256), data_range=images[i].max() - images[i].min())

    # Compute SSIM (specify data_range)
    ssim_before = structural_similarity(images[i], noisy_images[i], data_range=images[i].max() - images[i].min())
    ssim_after = structural_similarity(images[i], enhanced_images[i].reshape(256,256), data_range=images[i].max() - images[i].min())

    results.append([i+1, psnr_before, psnr_after, ssim_before, ssim_after])

df.to_csv("/content/enhancement_metrics.csv", index=False)
print("Metrics saved as enhancement_metrics.csv")

# =============================
# Step 1: Install dependencies
# =============================
!pip install -q bm3d scikit-image torchvision==0.15.2 torch==2.2.0 pillow tqdm tabulate

pip install bm3d

# =============================
# Step 2: Import libraries
# =============================
import os, cv2, random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from glob import glob
from bm3d import bm3d
from tqdm import tqdm
from tabulate import tabulate
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim


import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# =============================
# Step 3: Define dataset path
# =============================
# üîπ Replace 'MyMedicalImages' with your actual folder name inside /content/
base_dir = '/content/yes'  # <-- change this to your uploaded folder name

def get_image_paths(root, exts=('png','jpg','jpeg','tif','tiff','bmp')):
    paths=[]
    for ext in exts:
        paths += glob(f"{root}/**/*.{ext}", recursive=True)
    return sorted(paths)

img_paths = get_image_paths(base_dir)
print(f"‚úÖ Found {len(img_paths)} images in: {base_dir}")

# =============================
# Step 4: Preview few images
# =============================
n_show = min(10, len(img_paths))
fig, axs = plt.subplots(1, n_show, figsize=(4*n_show,4))
for i in range(n_show):
    im = Image.open(img_paths[i]).convert('L')
    axs[i].imshow(im, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(os.path.basename(img_paths[i]))
plt.show()

# =============================
# Step 5: Utility functions
# =============================
def read_gray(path):
    return np.array(Image.open(path).convert('L'), dtype=np.float32) / 255.0

def save_gray(img, path):
    Image.fromarray((np.clip(img,0,1)*255).astype(np.uint8)).save(path)

def compute_metrics(original, processed):
    return psnr(original, processed, data_range=1.0), ssim(original, processed, data_range=1.0)

# =============================
# Step 6: Classical Enhancement
# (BM3D denoising + Upscaling)
# =============================
os.makedirs('results/classical', exist_ok=True)
records = []
for p in tqdm(img_paths[:10], desc="Classical pipeline (BM3D)"):
    img = read_gray(p)
    denoised = bm3d(img, sigma_psd=0.05)
    upscaled = cv2.resize(denoised, (img.shape[1]*2, img.shape[0]*2), interpolation=cv2.INTER_CUBIC)
    orig_up = cv2.resize(img, (img.shape[1]*2, img.shape[0]*2), interpolation=cv2.INTER_CUBIC)
    ps, ss = compute_metrics(orig_up, upscaled)
    records.append((os.path.basename(p), ps, ss))
    comp = np.hstack([orig_up, upscaled])
    save_gray(comp, f"results/classical/{os.path.basename(p)}_bm3d.png")

print(tabulate(records, headers=['File','PSNR','SSIM']))
print("‚úÖ Classical enhanced images saved in results/classical/")

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import random
from tqdm import tqdm

# =============================
# Step 7: Deep Learning DnCNN (Fixed)
# =============================

class DnCNN(nn.Module):
    def __init__(self, channels=1, depth=17):
        super().__init__()
        layers = [nn.Conv2d(channels, 64, 3, 1, 1), nn.ReLU(inplace=True)]
        for _ in range(depth - 2):
            layers += [nn.Conv2d(64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)]
        layers.append(nn.Conv2d(64, channels, 3, 1, 1))
        self.net = nn.Sequential(*layers)
    def forward(self, x):
        return x - self.net(x)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("Using device:", device)

class MedDataset(Dataset):
    def __init__(self, paths, crop=128):
        self.paths = paths
        self.crop = crop
    def __len__(self):
        return len(self.paths)
    def __getitem__(self, i):
        img = read_gray(self.paths[i]).astype(np.float32)  # <-- ensure float32
        H, W = img.shape
        x, y = random.randint(0, H - self.crop), random.randint(0, W - self.crop)
        patch = img[x:x+self.crop, y:y+self.crop]
        noisy = np.clip(patch + np.random.normal(0, 0.05, patch.shape), 0, 1).astype(np.float32)
        return torch.tensor(noisy).unsqueeze(0), torch.tensor(patch).unsqueeze(0)

# ---- DataLoader ----
loader = DataLoader(MedDataset(img_paths, 128), batch_size=8, shuffle=True)

# ---- Model, optimizer, and loss ----
model = DnCNN().to(device)
opt = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

# ---- Training loop ----
for epoch in range(3):
    model.train()
    total = 0
    for noisy, clean in tqdm(loader, desc=f"Epoch {epoch+1}/3"):
        noisy, clean = noisy.to(device).float(), clean.to(device).float()  # <-- cast to float32
        out = model(noisy)
        loss = loss_fn(out, clean)
        opt.zero_grad()
        loss.backward()
        opt.step()
        total += loss.item()
    print(f"Avg loss: {total/len(loader):.6f}")

torch.save(model.state_dict(), "dncnn_model.pth")
print("‚úÖ Model trained and saved as dncnn_model.pth (float-safe)")

